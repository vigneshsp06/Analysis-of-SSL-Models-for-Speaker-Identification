{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-50c0c0358139fbe1\n",
      "Found cached dataset csv (/storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n",
      "100%|██████████| 3/3 [00:00<00:00, 186.13it/s]\n",
      "Loading cached sorted indices for dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-d89fbf7cda23da10.arrow\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorWithPadding,AutoModelForSequenceClassification, Trainer, TrainingArguments,AutoTokenizer,AutoModel,AutoConfig\n",
    "from transformers import default_data_collator\n",
    "from transformers import Wav2Vec2FeatureExtractor, HubertForSequenceClassification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import Dataset, Audio, Value, Features,load_dataset,ClassLabel\n",
    "from transformers import Wav2Vec2Processor\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "import numpy as np\n",
    "from transformers import AdamW,get_scheduler\n",
    "from datasets import load_metric\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "x = [str(i) for i in range(0,100,1)]\n",
    "features = Features(\n",
    "    {\n",
    "        \"id\": Value(\"string\"),\n",
    "        \"speaker_id\": Value(\"string\"), \n",
    "        'path': Value('string'),\n",
    "        \"audio\": Audio(sampling_rate=16000),\n",
    "        \"label\": ClassLabel(num_classes=100,names=x,names_file=None,id=None),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "dataset = load_dataset('csv', data_files={'train': 'train_100.csv', 'dev': 'dev_100.csv', 'test': 'test_100.csv',},features=features)\n",
    "dataset = dataset['test']\n",
    "dataset = dataset.sort(\"label\")\n",
    "sampling_rate = dataset.features[\"audio\"].sampling_rate\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"superb/hubert-base-superb-sid\")\n",
    "#feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"superb/wav2vec2-base-superb-sid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_duration = 10.0  # seconds\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    audio_arrays = [examples['audio'][i]['array'] for i in range(len(examples['id']))]\n",
    "#     audio_arrays = examples[\"audio\"]['array']\n",
    "#     audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays, \n",
    "        sampling_rate=feature_extractor.sampling_rate, \n",
    "        max_length=int(feature_extractor.sampling_rate * max_duration), \n",
    "        truncation=True,\n",
    "        padding=True\n",
    "\n",
    "    )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-2af97893ac7c8ce8.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-e4dfdb2ae8e3f15f.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-4b0784f67d2b4f03.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-c710592794e2fbac.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-2a30e5481fe0fc9f.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-a2873d75cd9901c2.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-898986f2044aad73.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-3a1c95db68122100.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-e89fdd6e058824b3.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-2ad2135e6affe25e.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-3d1ad8d5aed9ee41.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-4c80267571968725.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-b4a2231920373e34.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-f33ae60c3ae8c5a0.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-00f7d12a1c4cae7b.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-95de6a713f7d371d.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-fea893ef9d026e22.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-e9cba8ea2a015e60.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-177b43185b634054.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-ba1ccdd5303d292a.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-fa37e7a1a1b2e863.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-9a4ae993f94dfbf9.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-2d59173fb85d5bd4.arrow\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/csv/default-50c0c0358139fbe1/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-c0c70c5319f6a094.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'speaker_id', 'path', 'label', 'input_values', 'attention_mask'],\n",
       "    num_rows: 632\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.map(preprocess_function, remove_columns=[\"audio\"], batched=True,num_proc=24,batch_size=32)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.set_format(\"torch\",columns=[\"id\",\"input_values\",\"attention_mask\", \"label\"])\n",
    "# train_data_collator = default_data_collator\n",
    "# dev_data_collator = default_data_collator\n",
    "# test_data_collator = default_data_collator\n",
    "\n",
    "# train_dataloader = DataLoader(\n",
    "#     dataset[\"train\"], shuffle=True, batch_size=32, collate_fn=train_data_collator\n",
    "# )\n",
    "# dev_dataloader = DataLoader(\n",
    "#     dataset[\"dev\"], batch_size=32, collate_fn=dev_data_collator\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'speaker_id', 'path', 'label', 'input_values', 'attention_mask'],\n",
       "    num_rows: 632\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForSequenceClassification\n",
    "model_ft = HubertForSequenceClassification.from_pretrained(\"superb/hubert-base-superb-sid\")\n",
    "#model_ft = Wav2Vec2ForSequenceClassification.from_pretrained(\"superb/wav2vec2-base-superb-sid\")\n",
    "\n",
    "# model_ft = Wav2Vec2ForSequenceClassification.from_pretrained(\"superb/wav2vec2-base-superb-sid\")\n",
    "# feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"superb/wav2vec2-base-superb-sid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HubertForSequenceClassification(\n",
       "  (hubert): HubertModel(\n",
       "    (feature_extractor): HubertFeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): HubertGroupNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (1): HubertNoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (2): HubertNoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (3): HubertNoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (4): HubertNoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5): HubertNoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (6): HubertNoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): HubertFeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): HubertEncoder(\n",
       "      (pos_conv_embed): HubertPositionalConvEmbedding(\n",
       "        (conv): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "        (padding): HubertSamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0): HubertEncoderLayer(\n",
       "          (attention): HubertAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): HubertFeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): HubertEncoderLayer(\n",
       "          (attention): HubertAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): HubertFeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): HubertEncoderLayer(\n",
       "          (attention): HubertAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): HubertFeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): HubertEncoderLayer(\n",
       "          (attention): HubertAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): HubertFeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): HubertEncoderLayer(\n",
       "          (attention): HubertAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): HubertFeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): HubertEncoderLayer(\n",
       "          (attention): HubertAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): HubertFeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): HubertEncoderLayer(\n",
       "          (attention): HubertAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): HubertFeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): HubertEncoderLayer(\n",
       "          (attention): HubertAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): HubertFeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): HubertEncoderLayer(\n",
       "          (attention): HubertAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): HubertFeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): HubertEncoderLayer(\n",
       "          (attention): HubertAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): HubertFeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (10): HubertEncoderLayer(\n",
       "          (attention): HubertAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): HubertFeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (11): HubertEncoderLayer(\n",
       "          (attention): HubertAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): HubertFeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (projector): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (classifier): Linear(in_features=256, out_features=1251, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ft.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'speaker_id', 'path', 'label', 'input_values', 'attention_mask'],\n",
       "    num_rows: 632\n",
       "})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8275316455696202}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_name=\"accuracy\"\n",
    "metric = load_metric(metric_name)\n",
    "model_ft.eval()\n",
    "\n",
    "\n",
    "#dataset.set_format(\"torch\",columns=[\"id\",\"input_values\", \"attention_mask\", \"label\"])\n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset, batch_size=32, collate_fn=default_data_collator\n",
    ")\n",
    "\n",
    "predictions_list = []\n",
    "logits_list = []\n",
    "for batch in test_dataloader:\n",
    "#     print(batch.items())\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model_ft(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    logits_list.append(logits)\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    predictions_list = [y for x in [predictions_list, predictions] for y in x]\n",
    "    metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 1251])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id1 = dataset['id']\n",
    "logits\n",
    "predictions_list\n",
    "pred = dict(zip(id1, predictions_list))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset superb_demo (/storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/anton-l___superb_demo/si/1.9.0/77d23894ff429329a7fe80f9007cabb0deec321316f8dda1a1e9d10ffa089d08)\n",
      "Loading cached processed dataset at /storage/home/hcocice1/vprakash40/.cache/huggingface/datasets/anton-l___superb_demo/si/1.9.0/77d23894ff429329a7fe80f9007cabb0deec321316f8dda1a1e9d10ffa089d08/cache-68bfe8a618136781.arrow\n",
      "/storage/home/hcocice1/vprakash40/.conda/envs/ece6254/lib/python3.8/site-packages/transformers/configuration_utils.py:369: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import librosa\n",
    "from datasets import load_dataset\n",
    "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor\n",
    "\n",
    "def map_to_array(example):\n",
    "    speech, _ = librosa.load(example[\"file\"], sr=16000, mono=True)\n",
    "    example[\"speech\"] = speech\n",
    "    return example\n",
    "\n",
    "# load a demo dataset and read audio files\n",
    "dataset = load_dataset(\"anton-l/superb_demo\", \"si\", split=\"test\")\n",
    "dataset = dataset.map(map_to_array)\n",
    "\n",
    "model = Wav2Vec2ForSequenceClassification.from_pretrained(\"superb/wav2vec2-base-superb-sid\")\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"superb/hubert-base-superb-sid\")\n",
    "\n",
    "# compute attention masks and normalize the waveform if needed\n",
    "inputs = feature_extractor(dataset[:2][\"speech\"], sampling_rate=16000, padding=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': tensor([[ 0.0290,  0.0117,  0.0058,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0226, -0.0217, -0.0222,  ..., -0.0038, -0.0030, -0.0024]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ece6254]",
   "language": "python",
   "name": "conda-env-.conda-ece6254-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
